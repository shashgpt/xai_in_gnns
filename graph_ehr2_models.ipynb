{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53b96e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Tensor' from 'torch' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6024/136306074.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_compile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_compiling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch_geometric/typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mWITH_PT20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Tensor' from 'torch' (unknown location)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import DBLP\n",
    "from torch_geometric.nn import HGTConv, Linear\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d1f42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "seed_everything(42)\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7dccfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.001,\n",
       " 'weight_decay': 0.005,\n",
       " 'epochs': 200,\n",
       " 'train_ratio': 0.8,\n",
       " 'val_ratio': 0.1,\n",
       " 'test_ratio': 0.1,\n",
       " 'hidden_channels': 64,\n",
       " 'num_heads': 4,\n",
       " 'num_layers': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict()\n",
    "config[\"lr\"] = 0.001\n",
    "config[\"weight_decay\"] = 5e-3\n",
    "config[\"epochs\"] = 200\n",
    "config['train_ratio'] = 0.8\n",
    "config['val_ratio'] = 0.1\n",
    "config['test_ratio'] = 0.1\n",
    "config['hidden_channels'] = 64\n",
    "config['num_heads'] = 4\n",
    "config['num_layers'] = 2\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2255ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_features = torch.tensor(np.load('data/Processed/patient_features.npy')).to(torch.float32)\n",
    "procedure_features = torch.tensor(np.load('data/Processed/procedure_features.npy')).to(torch.float32)\n",
    "medication_features = torch.tensor(np.load('data/Processed/medication_features.npy')).to(torch.float32)\n",
    "lab_features = torch.tensor(np.load('data/Processed/lab_features.npy')).to(torch.float32)\n",
    "\n",
    "patient_edges = torch.tensor(np.load('data/Processed/patient_edges.npy'))\n",
    "procedure_edges = torch.tensor(np.load('data/Processed/procedures_edges.npy'))\n",
    "medication_edges = torch.tensor(np.load('data/Processed/medication_edges.npy'))\n",
    "lab_edges = torch.tensor(np.load('data/Processed/lab_edges.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f9a40f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1483 tensor([False, False,  True,  True,  True,  True,  True,  True,  True, False])\n",
      "1483 tensor([ True,  True, False, False, False, False, False, False, False,  True])\n",
      "1483 tensor([False, False, False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "num_patient_nodes = len(patient_features)\n",
    "num_train_nodes = int(config['train_ratio'] * num_patient_nodes)\n",
    "num_val_nodes = int(config['val_ratio'] * num_patient_nodes)\n",
    "num_test_nodes = num_patient_nodes - num_train_nodes - num_val_nodes\n",
    "\n",
    "# patient_nodes_indices = torch.arange(num_patient_nodes)\n",
    "# shuffled_indices = torch.randperm(num_patient_nodes)\n",
    "\n",
    "patient_nodes_indices = np.arange(num_patient_nodes)\n",
    "np.random.shuffle(patient_nodes_indices)\n",
    "shuffled_indices = torch.tensor(patient_nodes_indices)\n",
    "\n",
    "train_indices = shuffled_indices[:num_train_nodes]\n",
    "val_indices = shuffled_indices[num_train_nodes:num_train_nodes + num_val_nodes]\n",
    "test_indices = shuffled_indices[num_train_nodes + num_val_nodes:]\n",
    "\n",
    "train_mask = torch.zeros(num_patient_nodes, dtype=torch.bool)\n",
    "val_mask = torch.zeros(num_patient_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_patient_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[patient_nodes_indices[train_indices]] = True\n",
    "val_mask[patient_nodes_indices[val_indices]] = True\n",
    "test_mask[patient_nodes_indices[test_indices]] = True\n",
    "\n",
    "print(len(train_mask), train_mask[:10])\n",
    "print(len(val_mask), val_mask[:10])\n",
    "print(len(test_mask), test_mask[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753a6fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_heads, num_layers, num_pat, num_proc, num_med, num_lab, data):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        self.lin_dict[\"patient\"] = Linear(num_pat, hidden_channels)\n",
    "        self.lin_dict[\"procedure\"] = Linear(num_proc, hidden_channels)\n",
    "        self.lin_dict[\"medication\"] = Linear(num_med, hidden_channels)\n",
    "        self.lin_dict[\"lab\"] = Linear(num_lab, hidden_channels)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(), num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "\n",
    "        out = self.lin(x_dict['patient'])\n",
    "        out = F.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711295ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(feature_index, config, directory, label_name):\n",
    "    \n",
    "    labels = torch.tensor(np.load('data/Processed/MIMIC_y.npy')[:, feature_index]).to(torch.float32)\n",
    "    \n",
    "    data = HeteroData()\n",
    "    data['patient'].x = patient_features\n",
    "    data['patient'].y = labels\n",
    "    data['patient'].train_mask = train_mask\n",
    "    data['patient'].val_mask = val_mask\n",
    "    data['patient'].test_mask = test_mask\n",
    "    data['procedure'].x = procedure_features\n",
    "    data['medication'].x = medication_features\n",
    "    data['lab'].x = lab_features\n",
    "    data['patient', 'same_patient', 'patient'].edge_index = patient_edges\n",
    "    data['patient', 'proc_values', 'procedure'].edge_index = procedure_edges\n",
    "    data['patient', 'med_values', 'medication'].edge_index = medication_edges\n",
    "    data['patient', 'lab_values', 'lab'].edge_index = lab_edges\n",
    "    data = T.ToUndirected()(data)\n",
    "    data = data.to(device)\n",
    "    \n",
    "    model = HGT(hidden_channels=config['hidden_channels'], out_channels=1, num_heads=config['num_heads'], \n",
    "            num_layers=config['num_layers'], num_pat=3, num_proc=len(procedure_features), \n",
    "            num_med=len(medication_features), num_lab=len(lab_features), data=data).to(device)\n",
    "    \n",
    "    losses = []\n",
    "    auprc_val = []\n",
    "    auprc_test = []\n",
    "    auprc_train = []\n",
    "    acc_val = []\n",
    "    acc_test = []\n",
    "    acc_train = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "        mask = data['patient'].train_mask\n",
    "        loss = F.cross_entropy(out[mask].squeeze(), data['patient'].y[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc = ((out[mask].detach().cpu().numpy().squeeze()>0.5).astype(int) == data['patient'].y[mask].detach().cpu().numpy()).sum()/len(out[mask])\n",
    "        precision, recall, thresholds = precision_recall_curve(data[\"patient\"].y[mask].cpu().numpy(), out[mask].squeeze().detach().cpu().numpy())\n",
    "        train_auprc = auc(recall, precision)\n",
    "        return train_acc, train_auprc, float(loss)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test():\n",
    "        model.eval()\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "        val_mask = data['patient'].val_mask\n",
    "        precision, recall, thresholds = precision_recall_curve(data[\"patient\"].y[val_mask].cpu().numpy(), out[val_mask].squeeze().detach().cpu().numpy())\n",
    "        val_auprc = auc(recall, precision)\n",
    "        test_mask = data['patient'].test_mask\n",
    "        precision, recall, thresholds = precision_recall_curve(data[\"patient\"].y[test_mask].cpu().numpy(), out[test_mask].squeeze().detach().cpu().numpy())\n",
    "        test_auprc = auc(recall, precision)\n",
    "        val_acc = ((out[val_mask].detach().cpu().numpy().squeeze()>0.5).astype(int) == data['patient'].y[val_mask].detach().cpu().numpy()).sum()/len(out[val_mask])\n",
    "        test_acc = ((out[test_mask].detach().cpu().numpy().squeeze()>0.5).astype(int) == data['patient'].y[test_mask].detach().cpu().numpy()).sum()/len(out[test_mask])\n",
    "\n",
    "        return (val_auprc, test_auprc, val_acc, test_acc)\n",
    "\n",
    "        \n",
    "    logpath = directory + \"Log.txt\"\n",
    "    modelpath = directory + \"model.pth\"\n",
    "    \n",
    "    with open(logpath, 'w') as file:\n",
    "        print(\"LABEL:\", feature_index, label_name, file=file)\n",
    "        print(\"\\n\", file=file)\n",
    "                \n",
    "    for epoch in range(1, config[\"epochs\"]):\n",
    "        train_acc, train_auprc, loss = train()\n",
    "        val_auprc, test_auprc, val_acc, test_acc = test()\n",
    "        losses.append(loss)\n",
    "        auprc_train.append(train_auprc)\n",
    "        acc_train.append(train_acc)\n",
    "        auprc_val.append(val_auprc)\n",
    "        acc_val.append(val_acc)\n",
    "        auprc_test.append(test_auprc)\n",
    "        acc_test.append(test_acc)\n",
    "        with open(logpath, 'a') as file:\n",
    "            print(f'{epoch:03d}, Loss: {loss:.3f}, TrPRC: {train_auprc:.3f}, TrAcc: {train_acc:.3f}, VaPRC: {val_auprc:.3f}, VaAcc: {val_acc:.3f}, TePRC: {test_auprc:.3f}, TeAcc: {test_acc:.3f}', file=file)\n",
    "        \n",
    "    torch.save(model.state_dict(), modelpath)\n",
    "    np.save(directory + \"Train_AUPRC.npy\", auprc_train)\n",
    "    np.save(directory + \"Val_AUPRC.npy\", auprc_val)\n",
    "    np.save(directory + \"Test_AUPRC.npy\", auprc_test)\n",
    "    np.save(directory + \"Train_Acc.npy\", acc_train)\n",
    "    np.save(directory + \"Val_Acc.npy\", acc_val)\n",
    "    np.save(directory + \"Test_Acc.npy\", acc_test)\n",
    "    np.save(directory + \"Loss.npy\", losses)\n",
    "    \n",
    "    best_auprc_val = np.max(auprc_val)\n",
    "    best_auprc_train = auprc_train[np.argmax(auprc_val)]\n",
    "    best_auprc_test = auprc_test[np.argmax(auprc_val)]\n",
    "    best_acc_train = acc_train[np.argmax(auprc_val)]\n",
    "    best_acc_val = acc_val[np.argmax(auprc_val)]\n",
    "    best_acc_test = acc_test[np.argmax(auprc_val)]\n",
    "    \n",
    "    print(f'Task: {feature_index}, TrPRC: {best_auprc_train:.3f}, TrAcc: {best_acc_train:.3f}, VaPRC: {best_auprc_val:.3f}, VaAcc: {best_acc_val:.3f}, TePRC: {best_auprc_test:.3f}, TeAcc: {best_acc_test:.3f}')\n",
    "        \n",
    "    with open(logpath, 'a') as file:\n",
    "        print(\"\\n\", file=file)\n",
    "        print(f'Task: {feature_index}, TrPRC: {best_auprc_train:.3f}, TrAcc: {best_acc_train:.3f}, VaPRC: {best_auprc_val:.3f}, VaAcc: {best_acc_val:.3f}, TePRC: {best_auprc_test:.3f}, TeAcc: {best_acc_test:.3f}', file=file)\n",
    "    \n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.plot(losses)\n",
    "    plt.savefig(directory+\"Loss.png\")\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.title(\"Train AUPRC\")\n",
    "    plt.plot(auprc_train)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.savefig(directory+\"Train_AUPRC.png\")\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.title(\"Validation AUPRC\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.plot(auprc_val)\n",
    "    plt.savefig(directory+\"Val_AUPRC.png\")\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.title(\"Test AUPRC\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.plot(auprc_test)\n",
    "    plt.savefig(directory+\"Test_AUPRC.png\")\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.title(\"Train Acc\")\n",
    "    plt.plot(acc_train)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.savefig(directory+\"Train_Acc.png\")\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.title(\"Val Acc\")\n",
    "    plt.plot(acc_val)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.savefig(directory+\"Val_Acc.png\")\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.title(\"Test Acc\")\n",
    "    plt.plot(acc_test)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.savefig(directory+\"Test_Acc.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return (best_auprc_train, best_auprc_val, best_auprc_test, best_acc_train, best_acc_val, best_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ef66e",
   "metadata": {},
   "source": [
    "### Run everything once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1addc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"y_Expired\", \"y_Non.Adherence\", \"y_Developmental.Delay.Retardation\", \"y_Advanced.Heart.Disease\",\n",
    "          \"y_Advanced.Lung.Disease\", \"y_Schizophrenia.and.other.Psychiatric.Disorders\", \"y_Alcohol.Abuse\",\n",
    "          \"y_Other.Substance.Abuse\", \"y_Chronic.Pain.Fibromyalgia\", \"y_Chronic.Neurological.Dystrophies\",\n",
    "          \"y_Advanced.Cancer\", \"y_Depression\", \"y_Dementia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96e9c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(13):\n",
    "#     directory = \"GNN_Results/\" + str(i) + \"/\"\n",
    "#     label_name = label_names[i]\n",
    "#     get_results(i, config, directory, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92dbbd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 0 y_Expired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashank/.conda/envs/RA_work/lib/python3.6/site-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5e8f68dfc1db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlabel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mauprc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauprc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauprc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mavg_auprc_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mauprc_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mavg_auprc_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mauprc_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a096393d1ed9>\u001b[0m in \u001b[0;36mget_results\u001b[0;34m(feature_index, config, directory, label_name)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auprc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mval_auprc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_auprc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a096393d1ed9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'patient'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'patient'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/RA_work/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/RA_work/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log_softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "for i in range(13):\n",
    "    \n",
    "    auprc_best = 0\n",
    "    auprc_index = -1\n",
    "    \n",
    "    print(\"LABEL:\", i, label_names[i])\n",
    "    \n",
    "    avg_auprc_train = 0\n",
    "    avg_auprc_val = 0\n",
    "    avg_auprc_test = 0\n",
    "    \n",
    "    avg_acc_train = 0\n",
    "    avg_acc_val = 0\n",
    "    avg_acc_test = 0\n",
    "    \n",
    "    for j in range(3):\n",
    "        directory_name = \"GNN_Results/\" + str(i) + \"_\" + str(j) + \"/\"\n",
    "        \n",
    "        if os.path.exists(directory_name):\n",
    "            shutil.rmtree(directory_name)\n",
    "            \n",
    "        os.makedirs(directory_name)\n",
    "        \n",
    "        label_name = label_names[i]\n",
    "        auprc_train, auprc_val, auprc_test, acc_train, acc_val, acc_test = get_results(i, config, directory_name, label_name)\n",
    "        avg_auprc_train += auprc_train\n",
    "        avg_auprc_val += auprc_val\n",
    "        avg_auprc_test += auprc_test\n",
    "        avg_acc_train += acc_train\n",
    "        avg_acc_val += acc_val\n",
    "        avg_acc_test += acc_test\n",
    "        if(auprc_val > auprc_best):\n",
    "            auprc_best = auprc_val\n",
    "            auprc_index = j\n",
    "            \n",
    "    print(\"Train AVERAGES:\", avg_auprc_train/3, avg_acc_train/3)\n",
    "    print(\"Val AVERAGES:\", avg_auprc_val/3, avg_acc_val/3)\n",
    "    print(\"Test AVERAGES:\", avg_auprc_test/3, avg_acc_test/3)\n",
    "    print(\"BEST MODEL:\", auprc_index, auprc_best)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
